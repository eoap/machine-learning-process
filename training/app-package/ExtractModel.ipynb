{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Best Model to ONNX Format\n",
    "\n",
    "This notebook provides a step-by-step tutorial for exporting a selected model from the MLflow model registry to ONNX format. The converted model is saved within the inference Python module to support the development of a new Python application and the creation of an inference Docker image, which is then published to the designated container registry. \n",
    "\n",
    "> **Note**: This process has already been completed. However, users may need to repeat it with their own candidate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf2onnx onnxmltools onnxruntime onnx mlflow tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model in ONNX Format\n",
    "\n",
    "In the cells below, the user will download the best model artifact from the MLflow model registry and then save it in the ONNX format.\n",
    "\n",
    "> **Note:** You may need to decrease the `desired_test_accuracy` to find active runs in the MLflow model registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"MLFLOW_TRACKING_URI\": \"http://localhost:5000/\",\n",
    "    \"experiment_id\": \"EuroSAT_classification\",\n",
    "    \n",
    "}\n",
    "desired_test_accuracy = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for best run\n",
    "active_runs = (\n",
    "    mlflow.search_runs(\n",
    "        experiment_names=[params[\"experiment_id\"]],\n",
    "        filter_string=f\"metrics.test_accuracy > {desired_test_accuracy}\",\n",
    "        search_all_experiments=True,\n",
    "    )\n",
    "    .sort_values(by=[\"metrics.test_accuracy\", \"metrics.test_precision\"], ascending=False)\n",
    "    .reset_index()\n",
    "    .loc[0]\n",
    ")\n",
    "run_id = active_runs[\"run_id\"]\n",
    "print(f\"Selected run_id: {run_id}\")\n",
    "\n",
    "# Download just the .keras file\n",
    "model_uri = f\"runs:/{run_id}/model/model.keras/data/model.keras\"\n",
    "keras_path = mlflow.artifacts.download_artifacts(artifact_uri=model_uri)\n",
    "print(f\"Downloaded Keras file path: {keras_path}\")\n",
    "\n",
    "# Load the Keras v3 model\n",
    "keras_model = keras.models.load_model(keras_path)\n",
    "\n",
    "# Define input signature\n",
    "input_signature = [tf.TensorSpec([None, 64, 64, 12], tf.float32, name=\"input\")]\n",
    "\n",
    "@tf.function(input_signature=input_signature)\n",
    "def model_func(x):\n",
    "    return keras_model(x)\n",
    "\n",
    "# Convert to ONNX\n",
    "onnx_model, _ = tf2onnx.convert.from_function(\n",
    "    model_func,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    output_path=\"model.onnx\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Successfully saved model.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
