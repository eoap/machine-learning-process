{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training step\n",
    "This notebook provides step-by-step instructions on how to install the training module for tile-based classification and execute a training run to evaluate its performance.\n",
    "\n",
    "> Note: Before proceeding, make sure to select the correct kernel. In the top-right corner of the notebook, choose the Jupyter kernel named `Bash`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDG_RUNTIME_DIR=/workspace/.local\n",
      "RUNTIME=/workspace/machine-learning-process/runs\n",
      "/workspace/machine-learning-process/runs\n"
     ]
    }
   ],
   "source": [
    "export WORKSPACE=/workspace/machine-learning-process\n",
    "export RUNTIME=${WORKSPACE}/runs\n",
    "mkdir -p ${RUNTIME}\n",
    "cd ${RUNTIME}\n",
    "printenv | grep RUNTIME\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hatch environment\n",
    "\n",
    "The hatch environment provides a dedicated Python where the `make-ml-model` step dependencies are installed. This process can be done with hatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K∙●∙ Unpacking distribution (tar|gzip)                                            0/09.17 MiB/49.49 MiB\u001b[1AA\n",
      "\u001b[2K\u001b[32m.. \u001b[0m \u001b[1;35mCreating environment: default\u001b[0m0m\n",
      "\u001b[2K\u001b[32m  .\u001b[0m \u001b[1;35mInstalling project in development mode\u001b[0mt mode\u001b[0m\n",
      "\u001b[1A\u001b[2K\u001b[?25l\u001b[32m.  \u001b[0m \u001b[1;35mChecking dependencies\u001b[0m\n",
      "\u001b[2K\u001b[32m ..\u001b[0m \u001b[1;35mSyncing dependencies\u001b[0mencies\u001b[0m\n",
      "\u001b[1A\u001b[2K\n"
     ]
    }
   ],
   "source": [
    "cd ${WORKSPACE}/training/make-ml-model\n",
    "hatch env prune\n",
    "hatch env create default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the make-ml-model application \n",
    "\n",
    "First dump the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:42:43.564862: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 13:42:43.573013: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 13:42:43.621030: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 13:42:43.656655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747057363.673890     739 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747057363.678972     739 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747057363.695506     739 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057363.695531     739 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057363.695534     739 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057363.695536     739 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 13:42:43.699237: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-12 13:42:46,106: INFO: font_manager: generated new fontManager]\n",
      "[2025-05-12 13:42:47,270: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-12 13:42:47.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "Usage: tile-based-training [OPTIONS]\n",
      "\n",
      "  A selected model with highest evaluation metrics will making an inference on\n",
      "  a sentinel-2 L1C data\n",
      "\n",
      "Options:\n",
      "  --stac_reference, --sr TEXT     The url which point to STAC input reference\n",
      "                                  [default: https://raw.githubusercontent.com/\n",
      "                                  eoap/machine-learning-\n",
      "                                  process/main/training/app-package/EUROSAT-\n",
      "                                  Training-Dataset/catalog.json; required]\n",
      "  --BATCH_SIZE, --b INTEGER       BATCH_SIZE  [default: 2]\n",
      "  --CLASSES, --c INTEGER          Number of classes to train  [default: 10]\n",
      "  --DECAY, --d FLOAT              DECAY - model metadata  [default: 0.1]\n",
      "  --EPOCHS, --ep INTEGER          Number of epochs\n",
      "  --EPSILON, --e FLOAT            EPSILON - model metadata  [default: 1e-06]\n",
      "  --LEARNING_RATE, --lr FLOAT     LEARNING_RATE  [default: 0.0001]\n",
      "  --LOSS, --lo TEXT               loss function  [default:\n",
      "                                  categorical_crossentropy]\n",
      "  --MEMENTUM, --m FLOAT           MEMENTUM - model metadata  [default: 0.95]\n",
      "  --OPTIMIZER, --o TEXT           OPTIMIZER  [default: Adam]\n",
      "  --REGULARIZER, --r TEXT         REGULARIZER\n",
      "  --SAMPLES_PER_CLASS, --s INTEGER\n",
      "                                  number of sample for each class to train\n",
      "                                  model based on  [default: 10]\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "hatch run default:tile-based-training --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the user can check the MLFLOW_TRACKING_URI which defined as environment variable during deployment of the code-server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://my-mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "echo ${MLFLOW_TRACKING_URI} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the `tile-based-training` command line tool with the parameters:\n",
    "\n",
    "- stac_reference: https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json\n",
    "- BATCH_SIZE: 2 \n",
    "- CLASSES: 10 \n",
    "- DECAY: 0.1 \n",
    "- EPOCHS: 50 \n",
    "- EPSILON: 0.000001 \n",
    "- LEARNING_RATE: 0.0001 \n",
    "- LOSS: categorical_crossentropy \n",
    "- MEMENTUM: 0.95 \n",
    "- OPTIMIZER: Adam \n",
    "- REGULARIZER: None \n",
    "- SAMPLES_PER_CLASS: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your mlflow is running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:42:51.353632: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 13:42:51.354419: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 13:42:51.358270: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 13:42:51.369121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747057371.385913     786 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747057371.391298     786 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747057371.406897     786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057371.406925     786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057371.406928     786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747057371.406930     786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 13:42:51.411314: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-12 13:42:54,142: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-12 13:42:54.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "2025-05-12 13:42:55.531793: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "[2025-05-12 13:42:55,531: INFO: main: MLFLOW URI: http://my-mlflow:5000]\n",
      "[2025-05-12 13:42:55,532: INFO: main: /workspace/machine-learning-process/training/make-ml-model]\n",
      "[2025-05-12 13:42:55,532: INFO: main: \n",
      "=================================================================\n",
      "Device name is: None \n",
      "=================================================================]\n",
      "{'BATCH_SIZE': 2,\n",
      " 'CLASSES': 10,\n",
      " 'DECAY': 0.1,\n",
      " 'EPOCHS': 50,\n",
      " 'EPSILON': 1e-06,\n",
      " 'LEARNING_RATE': 0.0001,\n",
      " 'LOSS': 'categorical_crossentropy',\n",
      " 'MEMENTUM': 0.95,\n",
      " 'OPTIMIZER': 'Adam',\n",
      " 'REGULARIZER': 'None',\n",
      " 'SAMPLES_PER_CLASS': 10,\n",
      " 'stac_reference': 'https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json'}\n",
      "[2025-05-12 13:42:55,533: INFO: common: YAML file: params.yaml written successfully]\n",
      "[2025-05-12 13:42:55,533: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2025-05-12 13:42:55,535: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 13:42:55,538: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 13:42:55,538: INFO: common: created directory at: output]\n",
      "[2025-05-12 13:42:55,538: INFO: common: created directory at: src/tile_based_training/output/data_ingestion]\n",
      "DataIngestionConfig(root_dir='src/tile_based_training/output/data_ingestion', stac_reference='https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json', local_data_file='src/tile_based_training/output/data_ingestion', data_classes=BoxList(['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']), samples_per_class=10)\n",
      "[2025-05-12 13:42:55,538: INFO: data_ingestion: Accessing STAC endpoint]\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Fetching data from class AnnualCrop: 10it [00:00, 310.65it/s]\n",
      " 10%|████▍                                       | 1/10 [00:30<04:34, 30.53s/it]\n",
      "Fetching data from class Forest: 10it [00:00, 430.38it/s]\n",
      " 20%|████████▊                                   | 2/10 [01:03<04:16, 32.09s/it]\n",
      "Fetching data from class HerbaceousVegetation: 10it [00:00, 397.83it/s]\n",
      " 30%|█████████████▏                              | 3/10 [01:40<03:58, 34.05s/it]\n",
      "Fetching data from class Highway: 10it [00:00, 514.37it/s]\n",
      " 40%|█████████████████▌                          | 4/10 [02:15<03:28, 34.72s/it]\n",
      "Fetching data from class Industrial: 10it [00:00, 616.13it/s]\n",
      " 50%|██████████████████████                      | 5/10 [02:47<02:48, 33.68s/it]\n",
      "Fetching data from class Pasture: 10it [00:00, 601.77it/s]\n",
      " 60%|██████████████████████████▍                 | 6/10 [03:25<02:19, 34.95s/it]\n",
      "Fetching data from class PermanentCrop: 10it [00:00, 489.56it/s]\n",
      " 70%|██████████████████████████████▊             | 7/10 [03:37<01:22, 27.59s/it]\n",
      "Fetching data from class Residential: 10it [00:00, 489.02it/s]\n",
      " 80%|███████████████████████████████████▏        | 8/10 [04:13<01:00, 30.32s/it]\n",
      "Fetching data from class River: 10it [00:00, 556.90it/s]\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [04:52<00:33, 33.01s/it]\n",
      "Fetching data from class SeaLake: 10it [00:00, 358.30it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [05:29<00:00, 32.92s/it]\n",
      "[2025-05-12 13:48:26,163: INFO: data_ingestion: 100 items are loaded]\n",
      "[2025-05-12 13:48:26,166: INFO: data_ingestion: Train size: 60 , Valid size: 20, Test size: 20]\n",
      "[2025-05-12 13:48:26,167: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "=================================================================]\n",
      "[2025-05-12 13:48:26,167: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Prepare Base Model started <<<<<<]\n",
      "[2025-05-12 13:48:26,169: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 13:48:26,170: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 13:48:26,171: INFO: common: created directory at: output]\n",
      "[2025-05-12 13:48:26,171: INFO: common: created directory at: src/tile_based_training/output/prepare_base_model]\n",
      "\u001b[1mModel: \"sequential\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv2d (\u001b[94mConv2D\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)     │         \u001b[32m3,488\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation (\u001b[94mActivation\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m32\u001b[0m)     │         \u001b[32m9,248\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_1 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m18,496\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_2 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m36,928\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_3 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_1 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ flatten (\u001b[94mFlatten\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m12544\u001b[0m)          │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)                   │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │     \u001b[32m6,423,040\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_4 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_2 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_1 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)             │         \u001b[32m5,130\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_5 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)             │             \u001b[32m0\u001b[0m │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m6,496,330\u001b[0m (24.78 MB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m6,496,330\u001b[0m (24.78 MB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n",
      "[2025-05-12 13:48:26,502: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Prepare Base Model completed <<<<<<\n",
      "=================================================================]\n",
      "[2025-05-12 13:48:26,502: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Training Model started <<<<<<]\n",
      "[2025-05-12 13:48:26,505: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 13:48:26,506: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 13:48:26,506: INFO: common: created directory at: output]\n",
      "[2025-05-12 13:48:26,506: INFO: common: json file loaded succesfully from: src/tile_based_training/output/data_ingestion/splitted_data.json]\n",
      "[2025-05-12 13:48:26,507: INFO: common: json file loaded succesfully from: src/tile_based_training/output/data_ingestion/splitted_data.json]\n",
      "[2025-05-12 13:48:26,507: INFO: common: created directory at: src/tile_based_training/output/training]\n",
      "Loading data:  22%|██████▎                      | 13/60 [00:16<00:41,  1.14it/s][2025-05-12 13:48:44,112: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 5174']\n",
      "[2025-05-12 13:48:44,112: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 5174 bytes, expected 6656']\n",
      "[2025-05-12 13:48:44,112: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:48:44,112: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_997.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:48:54,474: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 5174']\n",
      "[2025-05-12 13:48:54,474: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 5174 bytes, expected 6656']\n",
      "[2025-05-12 13:48:54,474: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:48:54,474: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_997.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:49:09,889: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 5174']\n",
      "[2025-05-12 13:49:09,889: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 5174 bytes, expected 6656']\n",
      "[2025-05-12 13:49:09,889: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:49:09,889: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_997.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "Loading data:  52%|██████████████▉              | 31/60 [01:21<00:23,  1.21it/s][2025-05-12 13:49:53,275: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 13:50:07,943: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 13:50:27,959: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "Loading data:  80%|███████████████████████▏     | 48/60 [02:38<00:08,  1.35it/s][2025-05-12 13:51:11,024: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1295']\n",
      "[2025-05-12 13:51:11,024: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1295 bytes, expected 6656']\n",
      "[2025-05-12 13:51:11,024: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:51:11,024: INFO: common: GDAL signalled an error: err_no=1, msg='AnnualCrop_954.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:51:26,218: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1295']\n",
      "[2025-05-12 13:51:26,218: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1295 bytes, expected 6656']\n",
      "[2025-05-12 13:51:26,218: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:51:26,218: INFO: common: GDAL signalled an error: err_no=1, msg='AnnualCrop_954.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:51:46,044: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1295']\n",
      "[2025-05-12 13:51:46,044: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1295 bytes, expected 6656']\n",
      "[2025-05-12 13:51:46,044: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:51:46,044: INFO: common: GDAL signalled an error: err_no=1, msg='AnnualCrop_954.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "Loading data: 100%|█████████████████████████████| 60/60 [03:53<00:00,  3.89s/it]\n",
      "Loading data:  25%|███████▌                      | 5/20 [00:04<00:12,  1.17it/s][2025-05-12 13:52:29,210: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 13:52:29,210: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 13:52:29,210: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:52:29,210: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:52:45,021: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 13:52:45,022: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 13:52:45,022: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:52:45,022: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:53:05,162: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 13:53:05,163: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 13:53:05,163: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 13:53:05,163: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "Loading data:  75%|█████████████████████▊       | 15/20 [01:18<00:08,  1.63s/it]\r"
     ]
    }
   ],
   "source": [
    "hatch run default:tile-based-training \\\n",
    "    --stac_reference https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json \\\n",
    "    --BATCH_SIZE 2 \\\n",
    "    --CLASSES 10 \\\n",
    "    --DECAY 0.1 \\\n",
    "    --EPOCHS 50 \\\n",
    "    --EPSILON 0.000001 \\\n",
    "    --LEARNING_RATE 0.0001 \\\n",
    "    --LOSS categorical_crossentropy \\\n",
    "    --MEMENTUM 0.95 \\\n",
    "    --OPTIMIZER Adam \\\n",
    "    --REGULARIZER None \\\n",
    "    --SAMPLES_PER_CLASS 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m.\u001b[0m\n",
      "├── \u001b[0;33mconfig\u001b[0m\n",
      "│   └── config.yaml\n",
      "├── Dockerfile\n",
      "├── \u001b[0;33moutput\u001b[0m\n",
      "│   └── \u001b[0;33mlogs\u001b[0m\n",
      "│       └── running_logs.log\n",
      "├── params.yaml\n",
      "├── pyproject.toml\n",
      "└── \u001b[0;33msrc\u001b[0m\n",
      "    ├── __init__.py\n",
      "    └── \u001b[0;33mtile_based_training\u001b[0m\n",
      "        ├── __about__.py\n",
      "        ├── \u001b[0;33mcomponents\u001b[0m\n",
      "        │   ├── data_ingestion.py\n",
      "        │   ├── __init__.py\n",
      "        │   ├── model_evaluation.py\n",
      "        │   ├── prepare_base_model.py\n",
      "        │   ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   │   ├── data_ingestion.cpython-310.pyc\n",
      "        │   │   ├── data_ingestion.cpython-311.pyc\n",
      "        │   │   ├── data_ingestion.cpython-312.pyc\n",
      "        │   │   ├── __init__.cpython-310.pyc\n",
      "        │   │   ├── __init__.cpython-311.pyc\n",
      "        │   │   ├── __init__.cpython-312.pyc\n",
      "        │   │   ├── model_evaluation.cpython-310.pyc\n",
      "        │   │   ├── model_evaluation.cpython-311.pyc\n",
      "        │   │   ├── model_evaluation.cpython-312.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-310.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-311.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-312.pyc\n",
      "        │   │   ├── train_model.cpython-310.pyc\n",
      "        │   │   ├── train_model.cpython-311.pyc\n",
      "        │   │   └── train_model.cpython-312.pyc\n",
      "        │   └── train_model.py\n",
      "        ├── \u001b[0;33mconfig\u001b[0m\n",
      "        │   ├── configuration.py\n",
      "        │   ├── __init__.py\n",
      "        │   ├── params.yaml\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── configuration.cpython-310.pyc\n",
      "        │       ├── configuration.cpython-311.pyc\n",
      "        │       ├── configuration.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── \u001b[0;33mconstants\u001b[0m\n",
      "        │   ├── config.py\n",
      "        │   ├── __init__.py\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── config.cpython-310.pyc\n",
      "        │       ├── config.cpython-311.pyc\n",
      "        │       ├── config.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── \u001b[0;33mentity\u001b[0m\n",
      "        │   ├── config_entity.py\n",
      "        │   ├── __init__.py\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── config_entity.cpython-310.pyc\n",
      "        │       ├── config_entity.cpython-311.pyc\n",
      "        │       ├── config_entity.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── __init__.py\n",
      "        ├── main.py\n",
      "        ├── \u001b[0;33moutput\u001b[0m\n",
      "        │   └── \u001b[0;33mdata_ingestion\u001b[0m\n",
      "        ├── \u001b[0;33mpipeline\u001b[0m\n",
      "        │   ├── __init__.py\n",
      "        │   ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   │   ├── __init__.cpython-310.pyc\n",
      "        │   │   ├── __init__.cpython-311.pyc\n",
      "        │   │   ├── __init__.cpython-312.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-310.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-311.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-312.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-310.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-311.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-312.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-310.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-311.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-312.pyc\n",
      "        │   │   ├── stage_04_model_evaluation.cpython-310.pyc\n",
      "        │   │   ├── stage_04_model_evaluation.cpython-311.pyc\n",
      "        │   │   └── stage_04_model_evaluation.cpython-312.pyc\n",
      "        │   ├── stage_01_data_ingestion.py\n",
      "        │   ├── stage_02_prepare_base_model.py\n",
      "        │   ├── stage_03_model_training.py\n",
      "        │   └── stage_04_model_evaluation.py\n",
      "        ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   ├── __init__.cpython-310.pyc\n",
      "        │   ├── __init__.cpython-311.pyc\n",
      "        │   ├── __init__.cpython-312.pyc\n",
      "        │   ├── main.cpython-310.pyc\n",
      "        │   ├── main.cpython-311.pyc\n",
      "        │   └── main.cpython-312.pyc\n",
      "        └── \u001b[0;33mutils\u001b[0m\n",
      "            ├── common.py\n",
      "            ├── __init__.py\n",
      "            └── \u001b[0;33m__pycache__\u001b[0m\n",
      "                ├── common.cpython-310.pyc\n",
      "                ├── common.cpython-311.pyc\n",
      "                ├── common.cpython-312.pyc\n",
      "                ├── __init__.cpython-310.pyc\n",
      "                ├── __init__.cpython-311.pyc\n",
      "                └── __init__.cpython-312.pyc\n",
      "\n",
      "21 directories, 88 files\n"
     ]
    }
   ],
   "source": [
    "tree mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "exit\n",
    "rm -fr ${RUNTIME}/envs mlruns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
