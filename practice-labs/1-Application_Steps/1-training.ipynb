{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training step\n",
    "This notebook provides step-by-step instructions on how to install the training module for tile-based classification and execute a training run to evaluate its performance.\n",
    "\n",
    "> Note: Before proceeding, make sure to select the correct kernel. In the top-right corner of the notebook, choose the Jupyter kernel named `Bash`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDG_RUNTIME_DIR=/workspace/.local\n",
      "RUNTIME=/workspace/machine-learning-process/runs\n",
      "/workspace/machine-learning-process/runs\n"
     ]
    }
   ],
   "source": [
    "export WORKSPACE=/workspace/machine-learning-process\n",
    "export RUNTIME=${WORKSPACE}/runs\n",
    "mkdir -p ${RUNTIME}\n",
    "cd ${RUNTIME}\n",
    "printenv | grep RUNTIME\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hatch environment\n",
    "\n",
    "The hatch environment provides a dedicated Python where the `make-ml-model` step dependencies are installed. This process can be done with hatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m.  \u001b[0m \u001b[1;35mCreating environment: default\u001b[0m0m\n",
      "\u001b[2K\u001b[32m  .\u001b[0m \u001b[1;35mInstalling project in development mode\u001b[0mt mode\u001b[0m\n",
      "\u001b[1A\u001b[2K\u001b[?25l\u001b[32m.  \u001b[0m \u001b[1;35mChecking dependencies\u001b[0m\n",
      "\u001b[2K\u001b[32m   \u001b[0m \u001b[1;35mSyncing dependencies\u001b[0mencies\u001b[0m\n",
      "\u001b[1A\u001b[2K\n"
     ]
    }
   ],
   "source": [
    "cd ${WORKSPACE}/training/make-ml-model\n",
    "hatch env prune\n",
    "hatch env create default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the make-ml-model application \n",
    "\n",
    "First dump the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 11:23:01.789960: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 11:23:01.871866: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 11:23:01.971646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746703382.027739    6066 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746703382.033355    6066 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746703382.057401    6066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703382.057466    6066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703382.057471    6066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703382.057475    6066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 11:23:02.069788: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-08 11:23:05,059: INFO: font_manager: generated new fontManager]\n",
      "[2025-05-08 11:23:06,487: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-08 11:23:06.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "Usage: tile-based-training [OPTIONS]\n",
      "\n",
      "  A selected model with highest evaluation metrics will making an inference on\n",
      "  a sentinel-2 L1C data\n",
      "\n",
      "Options:\n",
      "  --stac_reference, --sr TEXT     The url which point to STAC input reference\n",
      "                                  [default: https://raw.githubusercontent.com/\n",
      "                                  eoap/machine-learning-\n",
      "                                  process/main/training/app-package/EUROSAT-\n",
      "                                  Training-Dataset/catalog.json; required]\n",
      "  --BATCH_SIZE, --b INTEGER       BATCH_SIZE  [default: 2]\n",
      "  --CLASSES, --c INTEGER          Number of classes to train  [default: 10]\n",
      "  --DECAY, --d FLOAT              DECAY - model metadata  [default: 0.1]\n",
      "  --EPOCHS, --ep INTEGER          Number of epochs\n",
      "  --EPSILON, --e FLOAT            EPSILON - model metadata  [default: 1e-06]\n",
      "  --LEARNING_RATE, --lr FLOAT     LEARNING_RATE  [default: 0.0001]\n",
      "  --LOSS, --lo TEXT               loss function  [default:\n",
      "                                  categorical_crossentropy]\n",
      "  --MEMENTUM, --m FLOAT           MEMENTUM - model metadata  [default: 0.95]\n",
      "  --OPTIMIZER, --o TEXT           OPTIMIZER  [default: Adam]\n",
      "  --REGULARIZER, --r TEXT         REGULARIZER\n",
      "  --SAMPLES_PER_CLASS, --s INTEGER\n",
      "                                  number of sample for each class to train\n",
      "                                  model based on  [default: 10]\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "hatch run default:tile-based-training --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the user can check the MLFLOW_TRACKING_URI which defined as environment variable during deployment of the code-server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://my-mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "echo ${MLFLOW_TRACKING_URI} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the `tile-based-training` command line tool with the parameters:\n",
    "\n",
    "- stac_reference: https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json\n",
    "- BATCH_SIZE: 2 \n",
    "- CLASSES: 10 \n",
    "- DECAY: 0.1 \n",
    "- EPOCHS: 50 \n",
    "- EPSILON: 0.000001 \n",
    "- LEARNING_RATE: 0.0001 \n",
    "- LOSS: categorical_crossentropy \n",
    "- MEMENTUM: 0.95 \n",
    "- OPTIMIZER: Adam \n",
    "- REGULARIZER: None \n",
    "- SAMPLES_PER_CLASS: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your mlflow is running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 11:31:35.154409: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 11:31:35.158655: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 11:31:35.167985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746703895.184961    7697 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746703895.190206    7697 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746703895.203235    7697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703895.203287    7697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703895.203291    7697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746703895.203300    7697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 11:31:35.208715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-08 11:31:38,119: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-08 11:31:38.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "2025-05-08 11:31:39.414431: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-05-08 11:31:39.414453: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-05-08 11:31:39.414457: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: code-server-deployment-6c65cc8dbb-7vspm\n",
      "2025-05-08 11:31:39.414460: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: code-server-deployment-6c65cc8dbb-7vspm\n",
      "2025-05-08 11:31:39.414532: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program. The library may be missing or provided via another object.\n",
      "2025-05-08 11:31:39.414552: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 535.230.2\n",
      "[2025-05-08 11:31:39,414: INFO: main: MLFLOW URI: http://my-mlflow:5000]\n",
      "[2025-05-08 11:31:39,414: INFO: main: /workspace/machine-learning-process/training/make-ml-model]\n",
      "[2025-05-08 11:31:39,414: INFO: main: \n",
      "=================================================================\n",
      "Device name is: None \n",
      "=================================================================]\n",
      "{'BATCH_SIZE': 2,\n",
      " 'CLASSES': 10,\n",
      " 'DECAY': 0.1,\n",
      " 'EPOCHS': 50,\n",
      " 'EPSILON': 1e-06,\n",
      " 'LEARNING_RATE': 0.0001,\n",
      " 'LOSS': 'categorical_crossentropy',\n",
      " 'MEMENTUM': 0.95,\n",
      " 'OPTIMIZER': 'Adam',\n",
      " 'REGULARIZER': 'None',\n",
      " 'SAMPLES_PER_CLASS': 10,\n",
      " 'stac_reference': 'https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json'}\n",
      "[2025-05-08 11:31:39,416: INFO: common: YAML file: params.yaml written successfully]\n",
      "[2025-05-08 11:31:39,416: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2025-05-08 11:31:39,418: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-08 11:31:39,419: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-08 11:31:39,420: INFO: common: created directory at: output]\n",
      "[2025-05-08 11:31:39,420: INFO: common: created directory at: src/tile_based_training/output/data_ingestion]\n",
      "DataIngestionConfig(root_dir='src/tile_based_training/output/data_ingestion', stac_reference='https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json', local_data_file='src/tile_based_training/output/data_ingestion', data_classes=BoxList(['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']), samples_per_class=10)\n",
      "[2025-05-08 11:31:39,420: INFO: data_ingestion: Accessing STAC endpoint]\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Fetching data from class AnnualCrop: 0it [00:00, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/10 [00:49<?, ?it/s]\n",
      "[2025-05-08 11:32:29,639: ERROR: main: Cannot locate timezone 'UTC': discover_tz_dir failed to find zoneinfo\n",
      "]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/main.py\", line 157, in run_tile_based_classification_training\n",
      "    obj.main()\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/pipeline/stage_01_data_ingestion.py\", line 26, in main\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/pipeline/stage_01_data_ingestion.py\", line 18, in main\n",
      "    all_urls = data_ingestion.stac_loader()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 58, in stac_loader\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 54, in stac_loader\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 44, in stac_loader\n",
      "    for item in tqdm(stac_table_to_items(table), desc=f\"Fetching data from class {class_name}\"):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_api.py\", line 140, in stac_table_to_items\n",
      "    yield from clean_batch.to_json_batch().iter_dicts()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_batch.py\", line 198, in to_json_batch\n",
      "    batch = convert_timestamp_columns_to_string(batch)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_from_arrow.py\", line 30, in convert_timestamp_columns_to_string\n",
      "    pc.strftime(column, format=\"%Y-%m-%dT%H:%M:%SZ\"),  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/pyarrow/compute.py\", line 264, in wrapper\n",
      "    return func.call(args, options, memory_pool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_compute.pyx\", line 393, in pyarrow._compute.Function.call\n",
      "  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n",
      "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
      "pyarrow.lib.ArrowInvalid: Cannot locate timezone 'UTC': discover_tz_dir failed to find zoneinfo\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/bin/tile-based-training\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/main.py\", line 206, in main\n",
      "    run_tile_based_classification_training()\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/click/core.py\", line 1161, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/click/core.py\", line 1082, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/click/core.py\", line 1443, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/click/core.py\", line 788, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/main.py\", line 163, in run_tile_based_classification_training\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/main.py\", line 157, in run_tile_based_classification_training\n",
      "    obj.main()\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/pipeline/stage_01_data_ingestion.py\", line 26, in main\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/pipeline/stage_01_data_ingestion.py\", line 18, in main\n",
      "    all_urls = data_ingestion.stac_loader()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 58, in stac_loader\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 54, in stac_loader\n",
      "    raise e\n",
      "  File \"/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/components/data_ingestion.py\", line 44, in stac_loader\n",
      "    for item in tqdm(stac_table_to_items(table), desc=f\"Fetching data from class {class_name}\"):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_api.py\", line 140, in stac_table_to_items\n",
      "    yield from clean_batch.to_json_batch().iter_dicts()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_batch.py\", line 198, in to_json_batch\n",
      "    batch = convert_timestamp_columns_to_string(batch)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/stac_geoparquet/arrow/_from_arrow.py\", line 30, in convert_timestamp_columns_to_string\n",
      "    pc.strftime(column, format=\"%Y-%m-%dT%H:%M:%SZ\"),  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/machine-learning-process/runs/envs/env_5/lib/python3.12/site-packages/pyarrow/compute.py\", line 264, in wrapper\n",
      "    return func.call(args, options, memory_pool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_compute.pyx\", line 393, in pyarrow._compute.Function.call\n",
      "  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n",
      "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
      "pyarrow.lib.ArrowInvalid: Cannot locate timezone 'UTC': discover_tz_dir failed to find zoneinfo\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "hatch run default:tile-based-training \\\n",
    "    --stac_reference https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json \\\n",
    "    --BATCH_SIZE 2 \\\n",
    "    --CLASSES 10 \\\n",
    "    --DECAY 0.1 \\\n",
    "    --EPOCHS 50 \\\n",
    "    --EPSILON 0.000001 \\\n",
    "    --LEARNING_RATE 0.0001 \\\n",
    "    --LOSS categorical_crossentropy \\\n",
    "    --MEMENTUM 0.95 \\\n",
    "    --OPTIMIZER Adam \\\n",
    "    --REGULARIZER None \\\n",
    "    --SAMPLES_PER_CLASS 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m.\u001b[0m\n",
      "├── \u001b[0;33mconfig\u001b[0m\n",
      "│   └── config.yaml\n",
      "├── Dockerfile\n",
      "├── \u001b[0;33moutput\u001b[0m\n",
      "│   └── \u001b[0;33mlogs\u001b[0m\n",
      "│       └── running_logs.log\n",
      "├── params.yaml\n",
      "├── pyproject.toml\n",
      "└── \u001b[0;33msrc\u001b[0m\n",
      "    ├── __init__.py\n",
      "    └── \u001b[0;33mtile_based_training\u001b[0m\n",
      "        ├── __about__.py\n",
      "        ├── \u001b[0;33mcomponents\u001b[0m\n",
      "        │   ├── data_ingestion.py\n",
      "        │   ├── __init__.py\n",
      "        │   ├── model_evaluation.py\n",
      "        │   ├── prepare_base_model.py\n",
      "        │   ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   │   ├── data_ingestion.cpython-310.pyc\n",
      "        │   │   ├── data_ingestion.cpython-311.pyc\n",
      "        │   │   ├── data_ingestion.cpython-312.pyc\n",
      "        │   │   ├── __init__.cpython-310.pyc\n",
      "        │   │   ├── __init__.cpython-311.pyc\n",
      "        │   │   ├── __init__.cpython-312.pyc\n",
      "        │   │   ├── model_evaluation.cpython-310.pyc\n",
      "        │   │   ├── model_evaluation.cpython-311.pyc\n",
      "        │   │   ├── model_evaluation.cpython-312.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-310.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-311.pyc\n",
      "        │   │   ├── prepare_base_model.cpython-312.pyc\n",
      "        │   │   ├── train_model.cpython-310.pyc\n",
      "        │   │   ├── train_model.cpython-311.pyc\n",
      "        │   │   └── train_model.cpython-312.pyc\n",
      "        │   └── train_model.py\n",
      "        ├── \u001b[0;33mconfig\u001b[0m\n",
      "        │   ├── configuration.py\n",
      "        │   ├── __init__.py\n",
      "        │   ├── params.yaml\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── configuration.cpython-310.pyc\n",
      "        │       ├── configuration.cpython-311.pyc\n",
      "        │       ├── configuration.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── \u001b[0;33mconstants\u001b[0m\n",
      "        │   ├── config.py\n",
      "        │   ├── __init__.py\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── config.cpython-310.pyc\n",
      "        │       ├── config.cpython-311.pyc\n",
      "        │       ├── config.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── \u001b[0;33mentity\u001b[0m\n",
      "        │   ├── config_entity.py\n",
      "        │   ├── __init__.py\n",
      "        │   └── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │       ├── config_entity.cpython-310.pyc\n",
      "        │       ├── config_entity.cpython-311.pyc\n",
      "        │       ├── config_entity.cpython-312.pyc\n",
      "        │       ├── __init__.cpython-310.pyc\n",
      "        │       ├── __init__.cpython-311.pyc\n",
      "        │       └── __init__.cpython-312.pyc\n",
      "        ├── __init__.py\n",
      "        ├── main.py\n",
      "        ├── \u001b[0;33moutput\u001b[0m\n",
      "        │   └── \u001b[0;33mdata_ingestion\u001b[0m\n",
      "        ├── \u001b[0;33mpipeline\u001b[0m\n",
      "        │   ├── __init__.py\n",
      "        │   ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   │   ├── __init__.cpython-310.pyc\n",
      "        │   │   ├── __init__.cpython-311.pyc\n",
      "        │   │   ├── __init__.cpython-312.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-310.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-311.pyc\n",
      "        │   │   ├── stage_01_data_ingestion.cpython-312.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-310.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-311.pyc\n",
      "        │   │   ├── stage_02_prepare_base_model.cpython-312.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-310.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-311.pyc\n",
      "        │   │   ├── stage_03_model_training.cpython-312.pyc\n",
      "        │   │   ├── stage_04_model_evaluation.cpython-310.pyc\n",
      "        │   │   ├── stage_04_model_evaluation.cpython-311.pyc\n",
      "        │   │   └── stage_04_model_evaluation.cpython-312.pyc\n",
      "        │   ├── stage_01_data_ingestion.py\n",
      "        │   ├── stage_02_prepare_base_model.py\n",
      "        │   ├── stage_03_model_training.py\n",
      "        │   └── stage_04_model_evaluation.py\n",
      "        ├── \u001b[0;33m__pycache__\u001b[0m\n",
      "        │   ├── __init__.cpython-310.pyc\n",
      "        │   ├── __init__.cpython-311.pyc\n",
      "        │   ├── __init__.cpython-312.pyc\n",
      "        │   ├── main.cpython-310.pyc\n",
      "        │   ├── main.cpython-311.pyc\n",
      "        │   └── main.cpython-312.pyc\n",
      "        └── \u001b[0;33mutils\u001b[0m\n",
      "            ├── common.py\n",
      "            ├── __init__.py\n",
      "            └── \u001b[0;33m__pycache__\u001b[0m\n",
      "                ├── common.cpython-310.pyc\n",
      "                ├── common.cpython-311.pyc\n",
      "                ├── common.cpython-312.pyc\n",
      "                ├── __init__.cpython-310.pyc\n",
      "                ├── __init__.cpython-311.pyc\n",
      "                └── __init__.cpython-312.pyc\n",
      "\n",
      "21 directories, 88 files\n"
     ]
    }
   ],
   "source": [
    "tree mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "exit\n",
    "rm -fr ${RUNTIME}/envs mlruns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
