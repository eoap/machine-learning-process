{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training step\n",
    "This notebook provides step-by-step instructions on how to install the training module for tile-based classification and execute a training run to evaluate its performance.\n",
    "\n",
    "> Note: Before proceeding, make sure to select the correct kernel. In the top-right corner of the notebook, choose the Jupyter kernel named `Bash`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDG_RUNTIME_DIR=/workspace/.local\n",
      "RUNTIME=/workspace/machine-learning-process/runs\n",
      "/workspace/machine-learning-process/runs\n"
     ]
    }
   ],
   "source": [
    "export WORKSPACE=/workspace/machine-learning-process\n",
    "export RUNTIME=${WORKSPACE}/runs\n",
    "mkdir -p ${RUNTIME}\n",
    "cd ${RUNTIME}\n",
    "printenv | grep RUNTIME\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hatch environment\n",
    "\n",
    "The hatch environment provides a dedicated Python where the `make-ml-model` step dependencies are installed. This process can be done with hatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K∙∙∙ Waiting on shared resource                                                  \n",
      "\u001b[2K\u001b[32m.. \u001b[0m \u001b[1;35mCreating environment: default\u001b[0m0m\n",
      "\u001b[2K\u001b[32m  .\u001b[0m \u001b[1;35mInstalling project in development mode\u001b[0mt mode\u001b[0m\n",
      "\u001b[1A\u001b[2K\u001b[?25l\u001b[32m.  \u001b[0m \u001b[1;35mChecking dependencies\u001b[0m\n",
      "\u001b[2K\u001b[32m   \u001b[0m \u001b[1;35mSyncing dependencies\u001b[0mencies\u001b[0m\n",
      "\u001b[1A\u001b[2K\n"
     ]
    }
   ],
   "source": [
    "cd ${WORKSPACE}/training/make-ml-model\n",
    "hatch env prune\n",
    "hatch env create default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the make-ml-model application \n",
    "\n",
    "First dump the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:46:46.361114: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 14:46:46.369642: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:46:46.423756: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:46:46.469253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747061206.519975    1783 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747061206.534276    1783 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747061206.628545    1783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061206.628572    1783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061206.628576    1783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061206.628579    1783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 14:46:46.638581: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-12 14:46:49,189: INFO: font_manager: generated new fontManager]\n",
      "[2025-05-12 14:46:50,346: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-12 14:46:50.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "Usage: tile-based-training [OPTIONS]\n",
      "\n",
      "  A selected model with highest evaluation metrics will making an inference on\n",
      "  a sentinel-2 L1C data\n",
      "\n",
      "Options:\n",
      "  --stac_reference, --sr TEXT     The url which point to STAC input reference\n",
      "                                  [default: https://raw.githubusercontent.com/\n",
      "                                  eoap/machine-learning-\n",
      "                                  process/main/training/app-package/EUROSAT-\n",
      "                                  Training-Dataset/catalog.json; required]\n",
      "  --BATCH_SIZE, --b INTEGER       BATCH_SIZE  [default: 2]\n",
      "  --CLASSES, --c INTEGER          Number of classes to train  [default: 10]\n",
      "  --DECAY, --d FLOAT              DECAY - model metadata  [default: 0.1]\n",
      "  --EPOCHS, --ep INTEGER          Number of epochs\n",
      "  --EPSILON, --e FLOAT            EPSILON - model metadata  [default: 1e-06]\n",
      "  --LEARNING_RATE, --lr FLOAT     LEARNING_RATE  [default: 0.0001]\n",
      "  --LOSS, --lo TEXT               loss function  [default:\n",
      "                                  categorical_crossentropy]\n",
      "  --MEMENTUM, --m FLOAT           MEMENTUM - model metadata  [default: 0.95]\n",
      "  --OPTIMIZER, --o TEXT           OPTIMIZER  [default: Adam]\n",
      "  --REGULARIZER, --r TEXT         REGULARIZER\n",
      "  --SAMPLES_PER_CLASS, --s INTEGER\n",
      "                                  number of sample for each class to train\n",
      "                                  model based on  [default: 10]\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "hatch run default:tile-based-training --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the user can check the MLFLOW_TRACKING_URI which defined as environment variable during deployment of the code-server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://my-mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "echo ${MLFLOW_TRACKING_URI} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the `tile-based-training` command line tool with the parameters:\n",
    "\n",
    "- stac_reference: https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json\n",
    "- BATCH_SIZE: 2 \n",
    "- CLASSES: 10 \n",
    "- DECAY: 0.1 \n",
    "- EPOCHS: 50 \n",
    "- EPSILON: 0.000001 \n",
    "- LEARNING_RATE: 0.0001 \n",
    "- LOSS: categorical_crossentropy \n",
    "- MEMENTUM: 0.95 \n",
    "- OPTIMIZER: Adam \n",
    "- REGULARIZER: None \n",
    "- SAMPLES_PER_CLASS: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your mlflow is running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:46:54.435264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 14:46:54.436021: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:46:54.439686: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:46:54.450275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747061214.468311    1845 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747061214.473466    1845 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747061214.487559    1845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061214.487589    1845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061214.487591    1845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747061214.487595    1845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 14:46:54.492010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[2025-05-12 14:46:57,187: INFO: common: created directory at: config]\n",
      "\u001b[32m2025-05-12 14:46:57.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtile_based_training.constants\u001b[0m:\u001b[36mwrite_yaml\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mYAML file: config/config.yaml written successfully\u001b[0m\n",
      "2025-05-12 14:46:58.464878: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "[2025-05-12 14:46:58,464: INFO: main: MLFLOW URI: http://my-mlflow:5000]\n",
      "[2025-05-12 14:46:58,465: INFO: main: /workspace/machine-learning-process/training/make-ml-model]\n",
      "[2025-05-12 14:46:58,465: INFO: main: \n",
      "=================================================================\n",
      "Device name is: None \n",
      "=================================================================]\n",
      "{'BATCH_SIZE': 2,\n",
      " 'CLASSES': 10,\n",
      " 'DECAY': 0.1,\n",
      " 'EPOCHS': 5,\n",
      " 'EPSILON': 1e-06,\n",
      " 'LEARNING_RATE': 0.0001,\n",
      " 'LOSS': 'categorical_crossentropy',\n",
      " 'MEMENTUM': 0.95,\n",
      " 'OPTIMIZER': 'Adam',\n",
      " 'REGULARIZER': 'None',\n",
      " 'SAMPLES_PER_CLASS': 10,\n",
      " 'stac_reference': 'https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json'}\n",
      "[2025-05-12 14:46:58,466: INFO: common: YAML file: params.yaml written successfully]\n",
      "[2025-05-12 14:46:58,466: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2025-05-12 14:46:58,468: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 14:46:58,470: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 14:46:58,470: INFO: common: created directory at: output]\n",
      "[2025-05-12 14:46:58,470: INFO: common: created directory at: src/tile_based_training/output/data_ingestion]\n",
      "DataIngestionConfig(root_dir='src/tile_based_training/output/data_ingestion', stac_reference='https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json', local_data_file='src/tile_based_training/output/data_ingestion', data_classes=BoxList(['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']), samples_per_class=10)\n",
      "[2025-05-12 14:46:58,470: INFO: data_ingestion: Accessing STAC endpoint]\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Fetching data from class AnnualCrop: 10it [00:00, 102.77it/s]\n",
      " 10%|████▍                                       | 1/10 [00:24<03:37, 24.18s/it]\n",
      "Fetching data from class Forest: 10it [00:00, 615.69it/s]\n",
      " 20%|████████▊                                   | 2/10 [00:52<03:33, 26.65s/it]\n",
      "Fetching data from class HerbaceousVegetation: 10it [00:00, 353.83it/s]\n",
      " 30%|█████████████▏                              | 3/10 [01:29<03:39, 31.34s/it]\n",
      "Fetching data from class Highway: 10it [00:00, 614.36it/s]\n",
      " 40%|█████████████████▌                          | 4/10 [02:08<03:25, 34.24s/it]\n",
      "Fetching data from class Industrial: 10it [00:00, 623.64it/s]\n",
      " 50%|██████████████████████                      | 5/10 [02:43<02:53, 34.79s/it]\n",
      "Fetching data from class Pasture: 10it [00:00, 512.01it/s]\n",
      " 60%|██████████████████████████▍                 | 6/10 [03:20<02:21, 35.26s/it]\n",
      "Fetching data from class PermanentCrop: 10it [00:00, 366.49it/s]\n",
      " 70%|██████████████████████████████▊             | 7/10 [03:56<01:46, 35.56s/it]\n",
      "Fetching data from class Residential: 10it [00:00, 431.32it/s]\n",
      " 80%|███████████████████████████████████▏        | 8/10 [04:32<01:11, 35.89s/it]\n",
      "Fetching data from class River: 10it [00:00, 427.34it/s]\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [05:04<00:34, 34.63s/it]\n",
      "Fetching data from class SeaLake: 10it [00:00, 457.37it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [05:21<00:00, 32.18s/it]\n",
      "[2025-05-12 14:52:21,400: INFO: data_ingestion: 100 items are loaded]\n",
      "[2025-05-12 14:52:21,403: INFO: data_ingestion: Train size: 60 , Valid size: 20, Test size: 20]\n",
      "[2025-05-12 14:52:21,403: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "=================================================================]\n",
      "[2025-05-12 14:52:21,404: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Prepare Base Model started <<<<<<]\n",
      "[2025-05-12 14:52:21,406: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 14:52:21,407: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 14:52:21,407: INFO: common: created directory at: output]\n",
      "[2025-05-12 14:52:21,407: INFO: common: created directory at: src/tile_based_training/output/prepare_base_model]\n",
      "\u001b[1mModel: \"sequential\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv2d (\u001b[94mConv2D\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)     │         \u001b[32m3,488\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation (\u001b[94mActivation\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m32\u001b[0m)     │         \u001b[32m9,248\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_1 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m62\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m32\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m18,496\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_2 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m31\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m36,928\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_3 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m29\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_1 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m14\u001b[0m, \u001b[32m64\u001b[0m)     │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ flatten (\u001b[94mFlatten\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m12544\u001b[0m)          │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)                   │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │     \u001b[32m6,423,040\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_4 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_2 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_1 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)             │         \u001b[32m5,130\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_5 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)             │             \u001b[32m0\u001b[0m │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m6,496,330\u001b[0m (24.78 MB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m6,496,330\u001b[0m (24.78 MB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n",
      "[2025-05-12 14:52:21,668: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Prepare Base Model completed <<<<<<\n",
      "=================================================================]\n",
      "[2025-05-12 14:52:21,668: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Training Model started <<<<<<]\n",
      "[2025-05-12 14:52:21,670: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 14:52:21,671: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 14:52:21,671: INFO: common: created directory at: output]\n",
      "[2025-05-12 14:52:21,672: INFO: common: json file loaded succesfully from: src/tile_based_training/output/data_ingestion/splitted_data.json]\n",
      "[2025-05-12 14:52:21,672: INFO: common: json file loaded succesfully from: src/tile_based_training/output/data_ingestion/splitted_data.json]\n",
      "[2025-05-12 14:52:21,672: INFO: common: created directory at: src/tile_based_training/output/training]\n",
      "Loading data:  23%|██████▊                      | 14/60 [00:19<00:53,  1.17s/it][2025-05-12 14:52:42,550: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1192']\n",
      "[2025-05-12 14:52:42,550: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1192 bytes, expected 6656']\n",
      "[2025-05-12 14:52:42,550: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:52:42,550: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_968.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:52:53,013: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1192']\n",
      "[2025-05-12 14:52:53,013: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1192 bytes, expected 6656']\n",
      "[2025-05-12 14:52:53,013: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:52:53,013: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_968.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:53:08,425: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 1192']\n",
      "[2025-05-12 14:53:08,425: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 1192 bytes, expected 6656']\n",
      "[2025-05-12 14:53:08,426: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:53:08,426: INFO: common: GDAL signalled an error: err_no=1, msg='Industrial_968.tif, band 1: IReadBlock failed at X offset 0, Y offset 2: TIFFReadEncodedStrip() failed.']\n",
      "Loading data:  53%|███████████████▍             | 32/60 [01:26<00:24,  1.14it/s][2025-05-12 14:53:53,682: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 14:54:08,916: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 14:54:29,227: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "Loading data:  82%|███████████████████████▋     | 49/60 [02:44<00:07,  1.43it/s][2025-05-12 14:55:10,315: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 14:55:24,315: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "[2025-05-12 14:55:43,054: INFO: __init__: GDAL signalled an error: err_no=1, msg='cpl_unzOpenCurrentFile() failed']\n",
      "Loading data: 100%|█████████████████████████████| 60/60 [03:53<00:00,  3.90s/it]\n",
      "Loading data:  25%|███████▌                      | 5/20 [00:03<00:09,  1.54it/s][2025-05-12 14:56:19,799: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 14:56:19,800: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 14:56:19,800: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:56:19,800: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:56:30,088: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 14:56:30,089: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 14:56:30,089: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:56:30,089: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:56:45,373: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3442']\n",
      "[2025-05-12 14:56:45,373: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3442 bytes, expected 6656']\n",
      "[2025-05-12 14:56:45,373: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:56:45,374: INFO: common: GDAL signalled an error: err_no=1, msg='PermanentCrop_987.tif, band 1: IReadBlock failed at X offset 0, Y offset 4: TIFFReadEncodedStrip() failed.']\n",
      "Loading data: 100%|█████████████████████████████| 20/20 [01:03<00:00,  3.19s/it]\n",
      "[2025-05-12 14:57:19,675: INFO: train_model: Device is: None, Built with CUDA: True]\n",
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.1760 - loss: 2.2842 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to src/tile_based_training/output/training/trained_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582ms/step - accuracy: 0.1618 - loss: 2.2858 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.3006 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.1052 - loss: 2.3094 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 0.1090 - loss: 2.3063 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.2952 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.1448 - loss: 2.2620 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.1410 - loss: 2.2615 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.2892 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.0969 - loss: 2.2145 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4: val_accuracy improved from 0.00000 to 0.15000, saving model to src/tile_based_training/output/training/trained_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - accuracy: 0.0979 - loss: 2.2173 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1500 - val_loss: 2.2823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1688 - loss: 2.2573 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5: val_accuracy did not improve from 0.15000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step - accuracy: 0.1625 - loss: 2.2429 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1500 - val_loss: 2.2791 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "[2025-05-12 14:57:23,829: INFO: train_model: Training completed and session cleared.]\n",
      "[2025-05-12 14:57:23,829: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Training Model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2025-05-12 14:57:23,830: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Evaluating Model started <<<<<<]\n",
      "[2025-05-12 14:57:23,832: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-12 14:57:23,833: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-12 14:57:23,833: INFO: common: created directory at: output]\n",
      "[2025-05-12 14:57:23,833: INFO: common: json file loaded succesfully from: src/tile_based_training/output/data_ingestion/splitted_data.json]\n",
      "[2025-05-12 14:57:23,834: INFO: common: created directory at: mlruns]\n",
      "[2025-05-12 14:57:25,831: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 719']\n",
      "[2025-05-12 14:57:25,832: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 995 bytes, expected 6656']\n",
      "[2025-05-12 14:57:25,832: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:57:25,832: INFO: common: GDAL signalled an error: err_no=1, msg='Highway_998.tif, band 1: IReadBlock failed at X offset 0, Y offset 0: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:57:36,102: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 719']\n",
      "[2025-05-12 14:57:36,103: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 995 bytes, expected 6656']\n",
      "[2025-05-12 14:57:36,103: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:57:36,103: INFO: common: GDAL signalled an error: err_no=1, msg='Highway_998.tif, band 1: IReadBlock failed at X offset 0, Y offset 0: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:57:51,373: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 719']\n",
      "[2025-05-12 14:57:51,374: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 995 bytes, expected 6656']\n",
      "[2025-05-12 14:57:51,374: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:57:51,374: INFO: common: GDAL signalled an error: err_no=1, msg='Highway_998.tif, band 1: IReadBlock failed at X offset 0, Y offset 0: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:58:30,463: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3128']\n",
      "[2025-05-12 14:58:30,464: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3128 bytes, expected 6656']\n",
      "[2025-05-12 14:58:30,464: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:58:30,464: INFO: common: GDAL signalled an error: err_no=1, msg='River_975.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:58:44,241: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3128']\n",
      "[2025-05-12 14:58:44,241: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3128 bytes, expected 6656']\n",
      "[2025-05-12 14:58:44,241: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:58:44,241: INFO: common: GDAL signalled an error: err_no=1, msg='River_975.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:59:03,618: INFO: common: GDAL signalled an error: err_no=1, msg='In file /io/gdal-3.9.3/port/cpl_vsil_gzip.cpp, at line 1214, decompression failed with z_err = -1, return = 3128']\n",
      "[2025-05-12 14:59:03,618: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip:Read error at scanline 4294967295; got 3128 bytes, expected 6656']\n",
      "[2025-05-12 14:59:03,618: INFO: common: GDAL signalled an error: err_no=1, msg='TIFFReadEncodedStrip() failed.']\n",
      "[2025-05-12 14:59:03,618: INFO: common: GDAL signalled an error: err_no=1, msg='River_975.tif, band 1: IReadBlock failed at X offset 0, Y offset 1: TIFFReadEncodedStrip() failed.']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1500 - loss: 2.3326 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "{'new_experiment': {'test_loss': 2.332581043243408, 'test_accuracy': 0.15000000596046448, 'test_precision': 0.0, 'test_recall': 0.0}}\n",
      "[2025-05-12 14:59:29,407: INFO: model_evaluation: MLFLOW_TRACKING_URI: http://my-mlflow:5000]\n",
      "2025/05/12 14:59:30 INFO mlflow.tracking.fluent: Experiment with name 'EuroSAT_classification' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'CNN'.\n",
      "2025/05/12 14:59:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: CNN, version 1\n",
      "Created version '1' of model 'CNN'.\n",
      "🏃 View run thundering-roo-978 at: http://my-mlflow:5000/#/experiments/1/runs/75324bdb9d7c46c0a4537bf2ca9013e8\n",
      "🧪 View experiment at: http://my-mlflow:5000/#/experiments/1\n",
      "[2025-05-12 14:59:39,120: INFO: main: \n",
      "=================================================================\n",
      ">>>>>> stage Evaluating Model completed <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "hatch run default:tile-based-training \\\n",
    "    --stac_reference https://raw.githubusercontent.com/eoap/machine-learning-process/main/training/app-package/EUROSAT-Training-Dataset/catalog.json \\\n",
    "    --BATCH_SIZE 2 \\\n",
    "    --CLASSES 10 \\\n",
    "    --DECAY 0.1 \\\n",
    "    --EPOCHS 5 \\\n",
    "    --EPSILON 0.000001 \\\n",
    "    --LEARNING_RATE 0.0001 \\\n",
    "    --LOSS categorical_crossentropy \\\n",
    "    --MEMENTUM 0.95 \\\n",
    "    --OPTIMIZER Adam \\\n",
    "    --REGULARIZER None \\\n",
    "    --SAMPLES_PER_CLASS 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the outputs:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/machine-learning-process/training/make-ml-model/src/tile_based_training/output\n",
      "├── data_ingestion\n",
      "│   └── splitted_data.json\n",
      "├── prepare_base_model\n",
      "│   └── base_model.keras\n",
      "└── training\n",
      "    └── trained_model.keras\n",
      "\n",
      "4 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "tree ${WORKSPACE}/training/make-ml-model/src/tile_based_training/output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user may train several tile-based classifiers using the `tile-based-training` module. One of the tracked artifacts through MLflow is the model's weights. The next step is to retrieve the best model, based on the desired evaluation metric, from the MLflow artifact registry and convert it to the ONNX format. This activity is explained in [\"Export the Best Model to ONNX Format\"](./ExtractModel.ipynb). Finally, this model can be integrated into the inference application package.\n",
    "\n",
    "> **Note:** This process has already been completed. However, users may need to repeat it with their own candidate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "rm -fr ${RUNTIME}/envs ${WORKSPACE}/training/make-ml-model/src/tile_based_training/output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
